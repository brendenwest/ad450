{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_natural_language_processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO4yNzaS4yzBytvTP1wmQoV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendenwest/ad450/blob/master/10_natural_language_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhAyzTiSvQ1D",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Processing\n",
        "\n",
        "### Reading\n",
        "- https://towardsdatascience.com/gentle-start-to-natural-language-processing-using-python-6e46c07addf3\n",
        "- https://towardsdatascience.com/introduction-to-natural-language-processing-for-text-df845750fb63\n",
        "\n",
        "### Tutorials\n",
        "- https://www.kaggle.com/learn/natural-language-processing\n",
        "- https://spacy.io/usage/spacy-101\n",
        "- https://www.datacamp.com/community/tutorials/stemming-lemmatization-python\n",
        "- https://www.datacamp.com/community/tutorials/machine-learning-hotel-reviews\n",
        "- https://www.datacamp.com/community/tutorials/simplifying-sentiment-analysis-python\n",
        "- https://realpython.com/natural-language-processing-spacy-python/\n",
        "\n",
        "### Practice\n",
        "- https://learn.datacamp.com/courses/introduction-to-natural-language-processing-in-python\n",
        "\n",
        "## Reference\n",
        "- [SPACy](https://spacy.io/usage/spacy-101)\n",
        "- [regular expressions](https://digitalfortress.tech/tricks/top-15-commonly-used-regex/)\n",
        "\n",
        "\n",
        "### Learning Outcomes\n",
        "- what is natural language processing\n",
        "- common Python libraries\n",
        "- word tokenization\n",
        "- stemming & lemmatization\n",
        "- n-grams\n",
        "- Text classification & sentiment analysis\n",
        "- word vectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV-oSeUcoU84",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "\n",
        "Natural Language Processing (NLP) applies data analysis and machine learning techniques to text and speech.\n",
        "\n",
        "Some common scenarios for NLP are:\n",
        "- word frequency analysis\n",
        "- sentiment analysis\n",
        "- plagiarism detection\n",
        "- text-to-speech\n",
        "- text-generation (chat bots)\n",
        "\n",
        "## Common libraries\n",
        "\n",
        "The Python ecosystem has two widely used NLP libraries that provide proven solutions for routine text-processing tasks:\n",
        "\n",
        "- [Natural Language ToolKit (NLTK](https://www.nltk.org/) \n",
        "- [spaCy](https://spacy.io/)\n",
        "\n",
        "In this course we'll focus on spaCy, but each is a solid choice with support for;\n",
        "- classification\n",
        "- tokenization\n",
        "- stemming\n",
        "- tagging \n",
        "- parsing \n",
        "- named-entity recognition\n",
        "- semantic reasoning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUs86KIS3ny9",
        "colab_type": "text"
      },
      "source": [
        "# Summary\n",
        "\n",
        "- **NLP** applies machine learning algorithms to text and speech.\n",
        "- **NLTK** (Natural Language Toolkit) is a leading Python library for NLP\n",
        "- **Sentence tokenization** divide a string of written language into its component sentences\n",
        "- **Word tokenization** divide a string of written language into its component words\n",
        "- **Stemming** and **Lemmatization** reduce word variants to a common base form.\n",
        "- **Stop words** are words which are filtered out before or after processing of text. They usually refer to the most common words in a language.\n",
        "- A **regular expression** is a sequence of characters that define a search pattern.**bold text**\n",
        "- The bag-of-words model is a simple feature extraction technique that describes the occurrence of each word within a document.\n",
        "- **TF-IDF** is a statistical measure used to evaluate a word's **importance**  to a document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPsedxF7ThrF",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oscXzCrUUjIY",
        "colab_type": "text"
      },
      "source": [
        "## Stemming & Lemmatization\n",
        "\n",
        "Stemming and lemmatization are special, but different, cases of **normalization**. \n",
        "\n",
        "- **Stemming** usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time.\n",
        "\n",
        "- **Lemmatization** uses vocabulary and morphological analysis of words to remove grammatical endings only and to return the base or dictionary form of a word (the **lemma**).\n",
        "\n",
        "a stemmer operates without knowledge of the context, and cannot understand the difference between words which have different meaning depending on part of speech. But the stemmers are easier to implement and usually run faster."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebe-sO8WTkHO",
        "colab_type": "text"
      },
      "source": [
        "## Word Vectors & Similarity\n",
        "\n",
        "Machine learning algorithms cannot work with raw text directly, so we convert the text into vectors of numbers (`word vectors` or `word embeddings`). \n",
        "\n",
        "Word vectors represent each word in a text numerically such that the vector corresponds to how that word is used or what it means. This allows algorithms to determine similarity of text.\n",
        "\n",
        "One common approach is the `bag-of-words` method, which describes the occurrence of every word within a document. The simplest method for scoring words in text is to mark the presence of words with 1 for present and 0 for absence. \n",
        "\n",
        "Other more complex algorithms, such as `word2vec` derive vectors that take account of the word's context. Words that appear in similar contexts will have similar vectors. Relations between words can be examined with mathematical (matrix) operations.\n",
        "\n"
      ]
    }
  ]
}