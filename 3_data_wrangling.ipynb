{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_data_wrangling.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM9iIw/1wOyAFZBY9zNDPnb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brendenwest/ad450/blob/master/3_data_wrangling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvEkzJWdJTUs",
        "colab_type": "text"
      },
      "source": [
        "# Data Wrangling\n",
        "\n",
        "Accessing and cleaning data is a crucial and often time-consuming step data science.\n",
        "\n",
        "Data scientists might use pure Python, psndas, or other programming tools for this step. Examples here focus on pandas, with a few other approaches for specific scenarios.\n",
        "\n",
        "### Reading\n",
        "\n",
        "- McKinney, Chapters 6 - 7\n",
        "- Molin, “Data Wrangling with Pandas”\n",
        "- https://www.detroitnews.com/story/news/local/detroit-city/housing/2020/01/09/detroit-homeowners-overtaxed-600-million/2698518001/\n",
        "- https://realpython.com/beautiful-soup-web-scraper-python/\n",
        "\n",
        "### Practice\n",
        "- https://www.datacamp.com/courses/importing-data-in-python-part-1\n",
        "- https://www.datacamp.com/courses/importing-data-in-python-part-2\n",
        "- https://www.datacamp.com/community/tutorials/making-web-crawlers-scrapy-python\n",
        "- https://www.datacamp.com/courses/cleaning-data-in-python (cleaning data for analysis)\n",
        "\n",
        "### Learning Outcomes\n",
        "- Loading data from text files\n",
        "- Working with common data formats\n",
        "- Web scraping and API interaction\n",
        "- Interacting with database\n",
        "- Inspecting data with pandas\n",
        "- Data cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1iFWoJEJYoo",
        "colab_type": "text"
      },
      "source": [
        "## Loading data files\n",
        "\n",
        "pandas has a number of built-in functions for reading tabular data from plain-text files into a dataframe, including these common formats:\n",
        "\n",
        "*   read_csv - comma-separated values\n",
        "*   read_table - tab-separated values (tsv)\n",
        "*   read_fwf - fixed-width columns\n",
        "*   read_html\n",
        "*   read_json - JavaScript object notation\n",
        "\n",
        "pandas' data-parsing functions support options for:\n",
        "- indexing\n",
        "- type inference and data conversion\n",
        "- datetime parsing\n",
        "- iterating over chunks of very large files\n",
        "- handling unclean data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaLOztqcZR80",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('sample_data/california_housing_test.csv')\n",
        "df = pd.read_table('sample_data/california_housing_test.csv', sep=\",\")\n",
        "df = pd.read_json('sample_data/anscombe.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhHE02VbaA63",
        "colab_type": "text"
      },
      "source": [
        "#### Common options:\n",
        "\n",
        "- handle files with no header\n",
        "- set a specific column as the dataframe index\n",
        "- set a hierarchichal index\n",
        "- skip specific rows\n",
        "- attempt to parse dates\n",
        "\n",
        "#### missing values\n",
        "\n",
        "pandas recognizes common strings for missing data, such as `NA` and `NULL`. \n",
        "\n",
        "Programs can also specify values to treat as missing and can use different values for different columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jdOZmrnj3DT",
        "colab_type": "text"
      },
      "source": [
        "#### Reading files in parts\n",
        "\n",
        "It sometimes makes sense to read part of a large file or iterate through it in small chunks.\n",
        "\n",
        "- `nrows` to read a small number or rows\n",
        "- `chunksize` to return a text parser object for iteration\n",
        "- using python's csv library:\n",
        "\n",
        "\n",
        "```\n",
        "# using python csv reader\n",
        "import csv\n",
        "f = open.('FILENAME')\n",
        "reader = csv.reader(f)\n",
        "for line in reader:\n",
        "  # operate on each line\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zZTNWPOkGCR",
        "colab_type": "text"
      },
      "source": [
        "### Working with JSON\n",
        "\n",
        "Programs can load JSON data with pandas `read_json` method or with core python.\n",
        "\n",
        "By default, `pandas.read_json` assumes each object in a JSON array is table row.\n",
        "\n",
        "```\n",
        "import json\n",
        "data = json.loads(FILENAME) # read JSON file into python object\n",
        "jsonfile = json.dumps(PYTHON_OBJECT) # convert python object to JSON\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be6OuSNqpJgU",
        "colab_type": "text"
      },
      "source": [
        "### Working with HTML\n",
        "\n",
        "pandas `read_html` method depends on several supporting libraries.\n",
        "\n",
        "```\n",
        "pip install lxml\n",
        "pip install beautifulsoup4 html5lib\n",
        "```\n",
        "\n",
        "By default it looks for & attempts to parse all TABLE elements in an HTML file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Ek2p_J7NM_",
        "colab_type": "text"
      },
      "source": [
        "### Working with Excel\n",
        "\n",
        "Programs can load data from Excel files using pandas `ExcelFile` method.\n",
        "\n",
        "```\n",
        "xlsx = pd.ExcelFile(FILENAME)\n",
        "pd.read_excel(xlsx, SHEETNAME)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stkYKkZXJeLT",
        "colab_type": "text"
      },
      "source": [
        "## Loading Web data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6nAYbw4AZIj",
        "colab_type": "text"
      },
      "source": [
        "Python programs can load data from web sites using a number of approaches, depending on:\n",
        "\n",
        "- whether data are available from an API\n",
        "- whether data are publicly available or behind authentication\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qINio3dtoCFg",
        "colab_type": "text"
      },
      "source": [
        "### Web API integration\n",
        "\n",
        "When data are available from an API as structured data (e.g. JSON, XML, CSV), programs can fetch using libraries such as `requests`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKY2U66UDuKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "url = 'https://data.seattle.gov/resource/jguv-t9rb.json'\n",
        "resp = requests.get(url)\n",
        "data = resp.json() # parse HTTP response\n",
        "licenses = pd.DataFrame(data)\n",
        "licenses.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-C4SqtJncE",
        "colab_type": "text"
      },
      "source": [
        "### Web scraping\n",
        "\n",
        "Sometimes data are available on the internet, but not as structured data. So programs need to capture a full web page and then extract just the desired data.\n",
        "\n",
        "Two widely used python libraries are:\n",
        "\n",
        "- BeautifulSoup - easy to use but requires other supporting libraries.\n",
        "- Scrapy - complete package & optimal for large, complicated tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hO-ArOUJzDi",
        "colab_type": "text"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "- handling dates\n",
        "- regular expressions\n",
        "- type conversion\n",
        "- Handling strings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yriT0CTxT-J",
        "colab_type": "text"
      },
      "source": [
        "### Handling missing data\n",
        "\n",
        "- detecting missing values\n",
        "- filtering missing values\n",
        "- filling in missing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY_Vd8j0xyG-",
        "colab_type": "text"
      },
      "source": [
        "### Transforming data\n",
        "\n",
        "- removing duplicates\n",
        "- transformation functions\n",
        "- replacing values\n",
        "- renaming indexes\n",
        "- categorizing & binning\n",
        "- handling outliers\n",
        "- dummy variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjMuGNj5yqve",
        "colab_type": "text"
      },
      "source": [
        "### String manipulation\n",
        "\n",
        "- string methods\n",
        "- regular expressions\n",
        "- vectorized string functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TrlbCTvJF0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}